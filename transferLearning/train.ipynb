{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn an image into a Feature Vector using Inception\n",
    "https://tfhub.dev/google/imagenet/inception_v3/feature_vector/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from getConfig import getConfig\n",
    "from mapImageToClass import mapImageToClass\n",
    "from formatData import formatData\n",
    "from createDataset import createDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Feature Vector (bottleneck) files for the images; map them to a Class, e.g. \"cat\"\n",
    "config = getConfig()\n",
    "imageClass, classIdx = mapImageToClass(config)\n",
    "# This process only works on the .npy so remove anything else\n",
    "for d in list(imageClass):\n",
    "    if \".npy\" not in d:\n",
    "        imageClass.pop(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numClasses = len(classIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDict = formatData(config, imageClass, classIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0824 17:23:10.609579 140560228796160 deprecation.py:323] From <ipython-input-7-c96593fc432b>:6: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "W0824 17:23:10.616796 140560228796160 deprecation.py:323] From /home/tbrownex/tensorflow/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "W0824 17:23:10.617967 140560228796160 deprecation.py:323] From /home/tbrownex/tensorflow/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "W0824 17:23:10.618953 140560228796160 deprecation.py:323] From /home/tbrownex/tensorflow/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "with tf.name_scope(\"inputPipeline\"):\n",
    "    trainDS = createDataset(dataDict, epochs, config, \"train\")\n",
    "    valDS = createDataset(dataDict, _, config, \"val\")\n",
    "    \n",
    "    iter = tf.data.Iterator.from_structure(trainDS.output_types, tf.compat.v1.data.get_output_shapes(trainDS))\n",
    "    features, labels = iter.get_next()\n",
    "    \n",
    "    trainInit = iter.make_initializer(trainDS)\n",
    "    valInit = iter.make_initializer(valDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0824 17:23:10.675489 140560228796160 deprecation.py:323] From <ipython-input-8-201c0ba903d1>:16: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L1 = numClasses\n",
    "STD = 1e-2\n",
    "LR = 5e-4\n",
    "bottleneckSize = 2048    # size of the Inception feature vector/bottleneck\n",
    "\n",
    "with tf.name_scope(\"Layer1\"):\n",
    "    l1w     = tf.Variable(tf.truncated_normal([bottleneckSize, L1], stddev=STD, dtype=tf.float32))\n",
    "    l1b     = tf.Variable(tf.truncated_normal([1,L1], dtype=tf.float32))\n",
    "    output = tf.matmul(features,l1w) + l1b\n",
    "\n",
    "with tf.name_scope(\"Accuracy\"):\n",
    "    preds = tf.math.argmax(output, axis=1)\n",
    "    actuals = tf.math.argmax(labels, axis=1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, actuals), tf.float32))\n",
    "\n",
    "xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=output)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimize = tf.train.AdamOptimizer(learning_rate=LR).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:    36 batches of size 32\n",
      "Validation: 6 batches of size 32\n"
     ]
    }
   ],
   "source": [
    "trainBatches = int(len(dataDict[\"trainX\"])/config[\"batchSize\"])\n",
    "print(\"Training:    {} batches of size {}\".format(trainBatches, config[\"batchSize\"]))\n",
    "valBatches = int(len(dataDict[\"valX\"])/config[\"batchSize\"])\n",
    "print(\"Validation: {} batches of size {}\".format(valBatches, config[\"batchSize\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   Loss    Accuracy\n",
      "1         0.75      81.77%\n",
      "2         0.56      84.90%\n",
      "3         0.48      85.94%\n",
      "4         0.44      85.42%\n",
      "5         0.39      87.50%\n",
      "6         0.38      87.50%\n",
      "7         0.37      86.46%\n",
      "8         0.35      88.02%\n",
      "9         0.33      90.10%\n",
      "10        0.32      90.10%\n",
      "11        0.34      89.58%\n",
      "12        0.32      90.62%\n",
      "13        0.31      90.62%\n",
      "14        0.32      90.62%\n",
      "15        0.29      92.19%\n",
      "16        0.29      90.62%\n",
      "17        0.30      92.71%\n",
      "18        0.28      91.67%\n",
      "19        0.28      91.67%\n",
      "20        0.27      91.67%\n",
      "21        0.27      91.15%\n",
      "22        0.28      90.62%\n",
      "23        0.28      92.19%\n",
      "24        0.27      91.67%\n",
      "25        0.27      91.67%\n",
      "26        0.28      91.67%\n",
      "27        0.26      91.67%\n",
      "28        0.26      91.67%\n",
      "29        0.26      91.67%\n",
      "30        0.26      91.67%\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "print(\"{:<8}{:<8}{}\".format(\"Epoch\", \"Loss\", \"Accuracy\"))\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(config[\"TBdir\"], sess.graph)\n",
    "    count=0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        sess.run(trainInit)\n",
    "        for _ in range(trainBatches):\n",
    "            sess.run(optimize)\n",
    "        # compute Loss against Val each epoch\n",
    "        sess.run(valInit)\n",
    "        totalLoss = 0\n",
    "        accList = []\n",
    "        for _ in range(valBatches):\n",
    "            l, acc = sess.run([loss, accuracy])\n",
    "            totalLoss += l\n",
    "            accList.append(acc)\n",
    "        print(\"{:<10}{:<10.2f}{:.2%}\".format(e+1, totalLoss/valBatches, np.array(accList).mean()))\n",
    "        sess.run(trainInit)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
